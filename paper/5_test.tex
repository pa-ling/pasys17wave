% !TEX root = main.tex

\section{Test}
%manuelle Tests?
%Testskripte
%Vergleich von seriell und parallel

\subsection{Manuelle Tests}
Da die geschrieben Programme nicht sehr groß und keine hohe Komplexität aufweisen, haben wir uns gegen Unit-Tests entschieden und testen von daher immer nur das komplette Programm bzw. rufen das Programm auf und nicht nur einen Teil (z.B. eine Funktion) auf.
Um verschiedene Konfigurationen der Anwendung zu testen gibt es mehrere Möglichkeiten. Man bearbeitet die Konfigurationsdatei entsprechend des Testszenarios und führt das Programm dann aus. Standardmäßig wird hierbei die Konfigurationsdatei "wave.conf" eingelesen. Es ist jedoch auch möglich als erstes Programmargument eine andere Konfigurationsdatei anzugeben. Schließlich kann OpenMP und auch OpenMPI über einen entsprechenden Parameter die Anzahl der zu nutzenden Threads/Prozesse übergeben werden.\\
%Hier grobe Angaben zur Testmaschine

\subsection{Automatisierte Tests}
Um schneller die Konfiguration zu ändern ist es zusätzlich möglich die Größe des Arrays (ARRAY\_SIZE) und die Anzahl der Simulationsschritte (SIMULATION\_STEPS) als zweites und drittes Programmargument anzugeben. Dieses Vorgehen ist jedoch nur für die automatisierten Tests gedacht. Dazu haben wir ein Shell-Skript erzeugt, welches welches ein Programm mit mehreren Konfigurationen ausführt. Details hierzu gibt es im nächsten Abschnitt.\\
Jede Konfiguration wird dabei zehn mal ausgeführt. Dabei wird die Zeit gemessen und nach den zehn Durchläufen wird die Durschnittszeit ermittelt und in eine Text-Datei geschrieben.
%Hier Angaben zum Testvorgehen und den Testwerten machen;

\subsection{Auswertung der Tests} %Alle Koordinatenpaare in diesem Abschnitt sollten überprüft/angepasst werden

Die beiden folgenden Diagramme stellen die Testergebnisse der Paralellisierung dar. Das erste Diagramm zeigt hierbei das Verhältnis zwischen der Ausführungszeit in Sekunden und der jeweiligen Punktmengen, welche bei der Simulation der Wellengleichung jeweils berechnet wurden.
Das zweite Diagramm legt den Speedup der beiden Parallelisierungslösungen zur sequentiell Lösung im Bezug auf die Ausführungszeit dar.
Zur leichteren Unterscheidung wurden die verschiedenen Lösungsansätze farblich hervorgehoben.
  
Bei der Analyse der drei Kurven in der Abbildung \ref{fig:diagramZeit} kann festgestellt werden, dass der Lösungsansatz mit OpenMPI die längste Ausführungszeit verursachte. Die dabei verursachte Ausführungszeit übersteigt den in blau dargestellten sequentiellen Lösungsansatz erheblich. Als Konsequenz daraus ist abzuleiten, dass diese Parallelisierungslösung nicht das angestrebte Projektziel erreicht hat. Ein Grund für die schlechten Performance der openMPI-Lösung stellt der hoher Verwaltungsaufwand dar, welche bei der Verteilung der Chunks vom Master an die Worker notwendig wird. Potenziell kann es außerdem zu Wartezeiten zwischen den Workern kommen, falls die Abarbeitung eines Worker bereits abgeschlossen ist und dieser bis zur erneuten Verteilung der Chunks auf den Master warten muss.

Der Lösungansatz unter Verwendung von OpenMP konnte im Vergleich zur OpenMPI-Lösung eine bessere Ausführungszeit erzielen. Im Vergleich mit der sequentiellen Lösung konnte dieser jedoch nicht den gewünschten Geschwindigkeitsvorteil bringen. Die Geschwindigkeit nährt sich im überwiegenden Teile der Testkurven der sequentiellen Lösung an. Jedoch kann bei hinreichend großen Punktmengen ein Geschwindigkeitsvorteil erzeugt werden. Diese ist im letzen Abschnitt der Kurve zu sehen.

\begin{figure}[H]
	\centering
	\begin{tikzpicture}
		\begin{axis}[
			%values
			xlabel = {Punktmenge},
			ylabel = {Zeit},
			xmin = 0, xmax = 20000000,
			ymin = 0, ymax = 100,
			xtick = {0, 5000000, 10000000, 15000000, 20000000},
			ytick = {0, 25, 50, 75, 100},
			%appearance
			legend pos = north west, %alternatives: e.g. (outer) north east
			legend cell align = left,
			legend style = {draw=none, font=\small},
			ymajorgrids = true,
			xmajorgrids = true,
			axis lines = left,
			grid style = solid,
			width = 13 cm,
			height = 8 cm
		]
		
		\legend{Sequentiell, OpenMP (2 Kerne), OpenMPI (2 Kerne)}
		
		\addplot[color=blue,mark=square*]
		coordinates {
			(0,0)(1000000,2)(5000000,13)(10000000,25)(20000000,53)
		};
		
		\addplot[color=red,mark=square*]
		coordinates {
			(0,0)(1000000,3)(5000000,15)(10000000,36)(20000000,49)
		};
	
		\addplot[color=darkgreen,mark=square*]
		coordinates {
			(0,0)(1000000,8)(5000000,41)(10000000,81)(20000000,158)
		};
		
		\end{axis}
	\end{tikzpicture}
	\caption{Zeit-Vergleich der Varianten für bestimmte Punktmengen}
	\label{fig:diagramZeit}
\end{figure}

In Abbildung \ref{fig:diagramSpeedUp} ist der Speedup von OpenMP und OpenMPI dargestellt. Die grüne Kurve zeigt hier bei die OpenMPI-Lösung. Der Speedup erreicht hier unabhängig von der zu simulierenden Punktmenge nicht mehr als 0,33 der sequentiellen Lösung. Somit ist keiner zeitliche Verbesserung festzustellen. Im Gegenteil, die sequentielle Ausgangslösung wäre im direkten Vergleich somit zu wählen.
Im Bezug auf die OpenMP-Lösung ist anhand des Kurvenverlaufs des Speedups ein Trend zur leichten Verbesserung der Ausführungszeit zu beobachten. Die Vermutung, dass die zu simulierende Punktmenge somit einen großen Einfluss auf die Ausführungszeit hat, wird damit bestätigt. Der maximale Speedup der OpenMP-Lösung betätigt mit Test 1,08. Die Parallelisierung hat deshalb im Zusammenhang einer hinreichend großen Punktmenge einen Geschwindigkeitsvorteil erzielt.

\begin{figure}[H]
	\centering
	\begin{tikzpicture}
		\begin{axis}[
		%values
		xlabel = {Punktmenge},
		ylabel = {SpeedUp},
		xmin = 0, xmax = 20000000,
		ymin = 0, ymax = 1.5,
		xtick = {0, 5000000, 10000000, 15000000, 20000000},
		ytick = {0, 0.25, 0.50, 0.75, 1, 1.25},
		%appearance
		legend pos = north west, %alternatives: e.g. (outer) north east
		legend cell align = left,
		legend style = {draw=none, font=\small},
		ymajorgrids = true,
		xmajorgrids = true,
		axis lines = left,
		grid style = solid,
		width = 13 cm,
		height = 8 cm
		]
		
		\legend{Seq. $\rightarrow$ OpenMP (2 Kerne), Seq. $\rightarrow$ OpenMPI (2 Kerne)}
		
		\addplot[color=red,mark=square*]
		coordinates {
			(0,0)(1000000,0.66)(5000000,0.86)(10000000,0.69)(20000000, 1.08)
		};
		
		\addplot[color=darkgreen,mark=square*]
		coordinates {
			(0,0)(1000000,0.25)(5000000,0.31)(10000000,0.30)(20000000,0.33)
		};
		
		\end{axis}
	\end{tikzpicture}
	\caption{SpeedUp-Vergleich von OpenMP und OpenMPI}
	\label{fig:diagramSpeedUp}
\end{figure}